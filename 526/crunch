#!/usr/bin/python3
# -*- coding: utf-8 -*-

# Copyright © 2013-2014 Martin Ueding <dev@martin-ueding.de>
# Licensed under The GNU Public License Version 2 (or later)

import json
import sys

import matplotlib.pyplot as pl
import numpy as np
import scipy.optimize as op
import scipy.misc
import scipy.stats
import matplotlib.pyplot as pl
import scipy.ndimage.filters
import unitprint

def gauss(x, mean, sigma, a):
    '''
    Einfache Normalverteilung, deren Integral durch ``a`` gegeben ist.
    '''
    return a / (np.sqrt(2 * np.pi) * sigma) \
            * np.exp(- (x - mean)**2/(2 * sigma**2))

def linear(x, a, b):
    '''
    Lineare Funktion.
    '''
    return a * x + b

def decay(x, tau, a):
    '''
    Exponentieller Abfall.
    '''
    return a * np.exp(- x / tau)

def cubic(x, a, b, c, d):
    '''
    Kubische Funktion.
    '''
    return a * x**3 + b * x**2 + c * x + d

def double_gauss(x, mean1, mean2, sigma1, sigma2, a, b):
    '''
    Summe von zwei Gaußfunktionen.
    '''
    return gauss(x, mean1, sigma1, a) + gauss(x, mean2, sigma2, b)

def fit_peak(T, filename, kind, lower, upper, p0, energy, show=False):
    '''
    Passt einen einzelnen Peak an.

    Als Seiteneffekt werden die Fitdaten in das Template dict geschrieben und
    die Fits in Plotdateien ausgegeben.

    :param T: Template dict
    :param filename: Dateiname mit Datenpunkten
    :param kind: ``double`` oder anderes
    :param lower: Unterer Index
    :param upper: Oberer Index
    :param p0: Anfangswerte für Fit
    :param energy: Energie, der dieser Peak entspricht
    :param show: Zeige Plot interaktiv an

    :return: Mittelpunkt, Fehler Mittelpunkt, Breite, Fehler Breite, Energie
    '''
    data = np.loadtxt(filename)
    bins = data[:, 0]
    counts = data[:, 1]

    fit_bins = bins[lower:upper]
    fit_counts = counts[lower:upper]

    x = np.linspace(np.min(fit_bins), np.max(fit_bins), 1000)

    if kind == 'double':
        popt, pconv = op.curve_fit(double_gauss, fit_bins, fit_counts, p0=p0)
        d = np.sqrt(pconv.diagonal())
        y = double_gauss(x, *popt)
        T['{}_mean_kanal'.format(energy)] = unitprint.siunitx(popt[1], d[1])
        T['{}_sigma'.format(energy)] = unitprint.siunitx(popt[3], d[3])
        np.savetxt('_build/fit_peak_{}.txt'.format(energy), np.column_stack([x, y]))

        return popt[1], d[1], abs(popt[3]), d[3], energy

    else:
        popt, pconv = op.curve_fit(gauss, fit_bins, fit_counts, p0=p0)
        d = np.sqrt(pconv.diagonal())
        y = gauss(x, *popt)
        T['{}_mean_kanal'.format(energy)] = unitprint.siunitx(popt[0], d[0])
        T['{}_sigma'.format(energy)] = unitprint.siunitx(popt[1], d[1])
        np.savetxt('_build/fit_peak_{}.txt'.format(energy), np.column_stack([x, y]))

        return popt[0], d[0], abs(popt[1]), d[1], energy


def interpolate_ansprech():
    '''
    Interpoliert die Ansprechwahrscheinlichkeit.

    Als Nebeneffekt wird die angepasste Funktion zum Plotten ausgegeben.

    :return: Umrechnungsfunktion Energie → Ansprechwahrscheinlichkeit.
    '''
    data = np.loadtxt('Ansprechwahrscheinlichkeit.csv')
    x = data[:, 0]
    y = data[:, 1]

    popt, pconv = op.curve_fit(cubic, x, y)

    converter = lambda x: cubic(x, *popt)

    fx = np.linspace(min(x), max(x), 1000)
    fy = converter(fx)

    np.savetxt('_build/Ansprech-fit.csv', np.column_stack([fx, fy]))

    return converter

def job_energieeichung(T):
    '''
    Eicht die Beziehung Kanal → Energie des Detektors.

    Dazu werden die bekannten Peaks der Spektren genommen und angepasst. Daran
    wird eine gerade angepasst mit fit_gauge_points().

    Diese Funktion gibt den Kontrollfluss an E_winkelabhaengigkeit() weiter.
    '''
    gauge_points = []

    gauge_points.append(fit_peak(T, 'Daten/01_Untergrund001.txt', 'single', 2700, 4000, [3300, 1400, 250], 662))

    spektrum = np.loadtxt('Daten/Spektrum_Ba001.txt')
    untergrund = np.loadtxt('Daten/Untergrund_Ba001.txt')
    spektrum[:,1] -= untergrund[:,1]

    np.savetxt('_build/Spektrum_Ba_korr.txt', spektrum)

    gauge_points.append(fit_peak(T, '_build/Spektrum_Ba_korr.txt', 'single', 85, 307, [178, 60, 5500], 31))
    gauge_points.append(fit_peak(T, '_build/Spektrum_Ba_korr.txt', 'single', 307, 670, [452, 90, 2450], 81))
    gauge_points.append(fit_peak(T, '_build/Spektrum_Ba_korr.txt', 'double', 1300, 2300, [1550, 1800, 100, 100, 800, 1100], 356))

    popt, pconv = fit_gauge_points(T, gauge_points)
    d = np.sqrt(pconv.diagonal())

    energie_winkel = peak_winkel(T, popt[0], popt[1], d[0], d[1])

    E_0 = 662e3

    E_winkelabhaengigkeit(T, E_0, energie_winkel)

def E_winkelabhaengigkeit(T, E_0, energie_winkel):
    energie_winkel = np.array(energie_winkel)
    E = energie_winkel[:,1]
    d_E = energie_winkel[:,4]

    phi = np.radians(energie_winkel[:,0])
    d_phi = np.radians(energie_winkel[:,3])

    m = 9.91e-31
    e = 1.6e-19
    c = 3e8

    P = 1e-3 / ( 1 + E_0*e/(m*c**2) * ( 1 - np.cos(phi) ) )
    d_P = np.sqrt(
            (1e-3 * E_0 * e / (m * c**2) * np.sin(phi) * P**2 * d_phi)**2
            #+ (1e-3 * e / (m * c**2) * (1 - np.cos(phi)) * P**2 * d_E_0)**2
            )

    np.savetxt('_build/E_winkelabhaengigkeit.txt', np.column_stack([P,E,d_P,d_E]))
    T['E_winkelabhaengigkeit'] = list(zip(
        unitprint.siunitx(E, d_E),
        unitprint.siunitx(phi, d_phi),
        unitprint.siunitx(P,d_P)
        ))
    x = np.linspace(np.min(P), np.max(P), 10)
    y = E_0*x
    np.savetxt('_build/E_winkelabhaengigkeit_ideal.txt', np.column_stack([x,y]))

    np.savetxt('_build/E_winkelabhaengigkeit_polar.txt', np.column_stack([
        np.degrees(phi),
        E,
        np.degrees(d_phi),
        d_E,
    ]))


def fit_gauge_points(T, points, show=False):
    '''
    Passt an Eichpunkte eine Gerade an und gibt die Fitparameter zurück.

    Als Nebeneffekt werden die Daten zum Plotten in Dateien geschrieben.
    '''
    p = np.array(points)
    channel_val = p[:, 0]
    channel_err = p[:, 1]
    width_val = p[:, 2]
    width_err = p[:, 3]
    energy = p[:, 4]

    popt, pconv = op.curve_fit(linear, channel_val, energy)

    d = np.sqrt(pconv.diagonal())

    points_table = np.column_stack([channel_val, energy, channel_err])
    np.savetxt('_build/data_energieeichung.txt', points_table)
    T['data_energieeichung'] = list(zip(
        unitprint.siunitx(channel_val, channel_err),
        unitprint.siunitx(width_val, width_err),
        unitprint.siunitx(energy),
    ))

    x = np.linspace(np.min(channel_val), np.max(channel_val), 10)
    y = linear(x, *popt)

    T['fit_energieeichung_steigung'] = unitprint.siunitx(popt[0], d[0])
    T['fit_energieeichung_offset'] = unitprint.siunitx(popt[1], d[1])

    if show:
        pl.plot(channel_val, energy, marker='+', linestyle='none')
        pl.plot(x, y)
        pl.show()

    np.savetxt('_build/fit_energieeichung.txt', np.column_stack([x, y]))

    return popt, pconv

def peak_winkel(T, energie_steigung_val, energie_offset_val, energie_steigung_err, energie_offset_err):
    '''
    Findet den Photopeak in allen Spektren.

    Dazu werden die Daten und der Untergrund geladen und voneinander abgezogen.
    Der größte Wert wird als Position des Photopeaks interpretiert. Dort wird
    eine Gaußkurve angepasst.

    Der Rückgabewert ist eine Liste mit Tupeln, die jeweils folgendes enthalten:

    - Winkel
    - Mittelpunkt
    - Integral
    - Fehler Winkel
    - Fehler Mittelpunkt
    - Fehler Integral
    '''
    energie_winkel = []
    d_winkel = .5
    for winkel in range(40, 121, 5):
        messdaten = np.loadtxt('Daten/plastik_{}deg001.txt'.format(winkel))
        messdaten_cut = messdaten[100:,:]
        untergrund = np.loadtxt('Daten/untergrund_{}deg001.txt'.format(winkel))
        untergrund_cut = untergrund[100:,:]

        ereignisse_val = messdaten_cut[:,1] - untergrund_cut[:,1]
        ereignisse_err = np.sqrt(
            np.sqrt(messdaten_cut[:,1])**2
            + np.sqrt(untergrund_cut[:,1])**2
        )

        energie_val = messdaten_cut[:,0] * energie_steigung_val + energie_offset_err
        energie_err = np.sqrt(
            (messdaten_cut[:,0] * energie_steigung_err)**2
            + (energie_offset_err)**2
        )

        # Exportiere umgerechnete Daten zum Plotten.
        np.savetxt(
            '_build/spektrum_{}deg_korr.txt'.format(winkel),
            np.column_stack([energie_val, ereignisse_val, energie_err, ereignisse_err])
        )

        max_index = np.argmax(ereignisse_val)
        lower = max(max_index - 450, 0)
        upper = min(max_index + 450, len(energie_val) - 1)

        fit_energie = energie_val[lower:upper]
        fit_ereignisse = ereignisse_val[lower:upper]

        popt, pconv = op.curve_fit(
            gauss,
            fit_energie,
            fit_ereignisse,
            p0=[
                np.mean(energie_val[max_index - 5:max_index + 5]),
                400,
                750
            ],
        )
        d = np.sqrt(pconv.diagonal())

        x = np.linspace(np.min(energie_val), np.max(energie_val), 1000)
        y = gauss(x, *popt)

        """
        print('lower', lower)
        print('upper', upper)
        print(energie.shape, ereignisse.shape)
        print(fit_energie.shape, fit_ereignisse.shape)

        print(pconv)

        pl.clf()
        pl.plot(energie, ereignisse)
        pl.plot(fit_energie, fit_ereignisse)
        pl.plot(x, y)
        pl.show()
        """

        np.savetxt('_build/fit_{}deg.txt'.format(winkel), np.column_stack([x,y]))

        energie_winkel.append((winkel, popt[0], popt[2], d_winkel, d[0], d[2]))

    np.savetxt('_build/data_energie_winkel.txt', energie_winkel)


    return energie_winkel


def extract_photo_peak(filename, dicke_mm):
    '''
    Extrahiert den Photopeak.

    An die Daten wird eine Gaußkurve an den Photopeak gefittet. Die Daten
    werden zum Plotten erneut ausgegeben.

    Rückgabewert ist ein Tupel mit:

    - Dicke [mm]
    - Integral
    - Fehler Integral
    - Schwerpunkt
    - Fehler Schwerpunkt
    - Breite
    - Fehler Breite
    '''
    data = np.loadtxt(filename)
    bins = data[:, 0]
    counts = data[:, 1]

    lower = 200
    upper = -1
    step = len(bins[lower:upper]) // 200

    bins = bins[lower:upper]
    counts = counts[lower:upper]

    lower_fit = 2700
    upper_fit = -1

    popt, pconv = op.curve_fit(
        gauss,
        bins[lower_fit:upper_fit],
        counts[lower_fit:upper_fit], 
        p0=[3000, 100, 120000],
    )

    y = gauss(bins, *popt)

    chisq, p = scipy.stats.chisquare(
        counts[lower_fit:upper_fit],
        y[lower_fit:upper_fit]
    )
    divisor = len(counts[lower_fit:upper_fit]) - 3 - 1

    np.savetxt('_build/plot-decay-data-{:02d}mm.txt'.format(dicke_mm), np.column_stack([
        bins, counts
    ]))
    np.savetxt('_build/plot-decay-used-{:02d}mm.txt'.format(dicke_mm), np.column_stack([
        bins[lower_fit:upper_fit], counts[lower_fit:upper_fit]
    ]))
    np.savetxt('_build/plot-decay-fit-{:02d}mm.txt'.format(dicke_mm), np.column_stack([
        bins[lower_fit:upper_fit], y[lower_fit:upper_fit]
    ]))

    c = np.sqrt(pconv.diagonal())

    return dicke_mm, popt[2], c[2], popt[0], c[0], popt[1], c[1]


def extinction_ratio(T, filename, dicke_mm):
    normal_data = np.loadtxt('Daten/01_Untergrund001.txt')
    normal_counts = normal_data[:, 1]
    data = np.loadtxt(filename)
    bins = data[:, 0]
    counts = data[:, 1]

    sigma = 50
    T['extinction_gauss_sigma'] = unitprint.siunitx(sigma)

    normal_counts = scipy.ndimage.filters.gaussian_filter(normal_counts, sigma)
    counts = scipy.ndimage.filters.gaussian_filter(counts, sigma)
    counts /= normal_counts

    counts_err = np.sqrt(
        (np.sqrt(counts) / normal_counts)**2
        + (counts / normal_counts**2 * np.sqrt(normal_counts))**2
    )

    lower = 200
    upper = -1
    step = len(bins[lower:upper]) // 200

    bins = bins[lower:upper:step]
    counts = counts[lower:upper:step]
    counts_err = counts_err[lower:upper:step]

    np.savetxt('_build/plot-ratio-{:02d}mm.txt'.format(dicke_mm), np.column_stack([
        bins, counts, counts_err
    ]))

def absorption(T):
    extinction_ratio(T, 'Daten/01_Untergrund001.txt', 0)
    extinction_ratio(T, 'Daten/1mm_Al_0deg001.txt', 1)
    extinction_ratio(T, 'Daten/5mm_Al_0deg001.txt', 5)
    extinction_ratio(T, 'Daten/10mm_Al_0deg001.txt', 10)
    extinction_ratio(T, 'Daten/20mm_Al_0deg001.txt', 20)
    extinction_ratio(T, 'Daten/50mm_Al_0deg001.txt', 50)

    points = []
    points.append(extract_photo_peak('Daten/01_Untergrund001.txt', 0))
    points.append(extract_photo_peak('Daten/1mm_Al_0deg001.txt', 1))
    points.append(extract_photo_peak('Daten/5mm_Al_0deg001.txt', 5))
    points.append(extract_photo_peak('Daten/10mm_Al_0deg001.txt', 10))
    points.append(extract_photo_peak('Daten/20mm_Al_0deg001.txt', 20))
    points.append(extract_photo_peak('Daten/50mm_Al_0deg001.txt', 50))

    points = np.array(points)


    dicke = points[:, 0]
    ampl_val = points[:, 1]
    ampl_err = points[:, 2]
    mean_val = points[:, 3]
    mean_err = points[:, 4]
    sigma_val = points[:, 5]
    sigma_err = points[:, 6]

    popt, pconv = op.curve_fit(
        decay,
        dicke[:-1],
        ampl_val[:-1],
        p0=[20, 420000],
        sigma=ampl_err[:-1],
    )
    x = np.linspace(np.min(dicke), np.max(dicke), 100)
    y = decay(x, *popt)
    
    c = np.sqrt(pconv.diagonal())

    pl.errorbar(dicke, ampl_val, ampl_err)
    pl.plot(x, y)
    #pl.show()

    np.savetxt('_build/plot-decay-data.txt', np.column_stack([dicke, ampl_val, ampl_err]))
    np.savetxt('_build/plot-decay-fit.txt', np.column_stack([x, y]))

    T['decay_table'] = list(zip(
        unitprint.siunitx(dicke),
        unitprint.siunitx(ampl_val, ampl_err),
        unitprint.siunitx(mean_val, mean_err),
        unitprint.siunitx(sigma_val, sigma_err),
    ))

    dichte = 2.7
    amu = 26.98
    na = 6.022e23

    n = dichte * na / amu

    sigma_val = popt[0] / n
    sigma_err = c[0] / n

    T['alu_dichte'] = unitprint.siunitx(dichte)
    T['alu_amu'] = unitprint.siunitx(amu)
    T['alu_n'] = unitprint.siunitx(n)
    T['alu_a'] = unitprint.siunitx(popt[0], c[0])
    T['alu_sigma'] = unitprint.siunitx(sigma_val / 1e-22, sigma_err / 1e-22)


def sigma_omega_klein_nishina(gamma, theta):
    '''
    Differentieller Wirkungsquerschnitt aus der Klein-Nishina-Formel.

    :param gamma: Photonenenergie
    :param theta: Ablenkwinkel
    :return: Differentieller Wirkungsquerschnitt
    '''
    re = 1e-15

    cos = np.cos(theta)

    return re**2 / 2 \
            * \
            1 / (1 + gamma * (1 - cos))**2 \
            * \
            (1 + cos**2 + (gamma**2 * (1 - cos)**2) / (1 + gamma * (1 - cos)))


def task_nishina_theorie(T):
    '''
    Erzeugt Dateien mit theoretischen Klein-Nishina-Plots.
    '''
    theta = np.linspace(0, np.pi, 1000)

    sigma_omega = sigma_omega_klein_nishina(0.01, theta)
    np.savetxt('_build/plot_klein_nishina_1.txt',
               np.column_stack([np.degrees(theta), sigma_omega]))

    sigma_omega = sigma_omega_klein_nishina(0.1, theta)
    np.savetxt('_build/plot_klein_nishina_2.txt',
               np.column_stack([np.degrees(theta), sigma_omega]))

    sigma_omega = sigma_omega_klein_nishina(1, theta)
    np.savetxt('_build/plot_klein_nishina_3.txt',
               np.column_stack([np.degrees(theta), sigma_omega]))

    sigma_omega = sigma_omega_klein_nishina(10, theta)
    np.savetxt('_build/plot_klein_nishina_4.txt',
               np.column_stack([np.degrees(theta), sigma_omega]))

def test_keys(T):
    '''
    Testet das dict auf Schlüssel mit Bindestrichen.
    '''
    dash_keys = []
    for key in T:
        if '-' in key:
            dash_keys.append(key)

    if len(dash_keys) > 0:
        print()
        print('**************************************************************')
        print('* Es dürfen keine Bindestriche in den Schlüsseln für T sein! *')
        print('**************************************************************')
        print()
        print('Folgende Schlüssel enthalten Bindestriche:')
        for dash_key in dash_keys:
            print('-', dash_key)
        print()
        sys.exit(100)


def main():
    T = {}

    task_nishina_theorie(T)
    absorption(T)
    job_energieeichung(T)

    interpolate_ansprech()

    test_keys(T)
    with open('_build/template.js', 'w') as f:
        json.dump(dict(T), f, indent=4, sort_keys=True)

if __name__ == "__main__":
    main()
